{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":4,"outputs":[{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsample = test[:500]\ntrain.head()","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_sample = train[train['keyword'].notnull()]\nnew_sample.head()","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"    id keyword                        location  \\\n15  46  ablaze                          London   \n16  47  ablaze  Niall's place | SAF 12 SQUAD |   \n17  51  ablaze                         NIGERIA   \n18  58  ablaze                  Live On Webcam   \n19  60  ablaze        Los Angeles, Califnordia   \n\n                                                 text  \n15  Birmingham Wholesale Market is ablaze BBC News...  \n16  @sunkxssedharry will you wear shorts for race ...  \n17  #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...  \n18  Check these out: http://t.co/rOI2NSmEJJ http:/...  \n19  PSA: IÛªm splitting my personalities.\\n\\n?? t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>46</td>\n      <td>ablaze</td>\n      <td>London</td>\n      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>47</td>\n      <td>ablaze</td>\n      <td>Niall's place | SAF 12 SQUAD |</td>\n      <td>@sunkxssedharry will you wear shorts for race ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>51</td>\n      <td>ablaze</td>\n      <td>NIGERIA</td>\n      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>58</td>\n      <td>ablaze</td>\n      <td>Live On Webcam</td>\n      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>60</td>\n      <td>ablaze</td>\n      <td>Los Angeles, Califnordia</td>\n      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**import libraries**\nfirst things first import all the needed libraries here"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sn\nfrom matplotlib import pyplot as plt\nfrom string import punctuation\nimport re\nimport nltk","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('wordnet')","execution_count":11,"outputs":[{"output_type":"stream","text":"[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n[nltk_data]     failure in name resolution>\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"False"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemm = WordNetLemmatizer()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n# from sklearn\nfrom sklearn.preprocessing import OneHotEncoder\n\nstopwords = nltk.corpus.stopwords.words('english')\n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TweetTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        new_X = X.copy()\n        new_X['no_punct_tweet'] = new_X.apply(lambda x: \"\".join([word.lower() for word in x['text'] if word not in punctuation]), axis=1)\n#         new_X['tokenize_tweet'] = new_X['no_punct_tweet'].apply(lambda x: re.split(r\"\\W+\", x), axis = 1)\n#         new_X['tokenize_tweet'] = new_X.apply(lambda x: re.split(r\"\\W+\", x['no_punct_tweet']), axis = 1)\n        new_X['tokenize_tweet'] = new_X.apply(lambda x: nltk.word_tokenize(x['no_punct_tweet']), axis=1)\n        new_X['no_stopwords_tweet'] = new_X.apply(lambda x: [word for word in x['tokenize_tweet'] if word not in stopwords], axis=1)\n        new_X['lemm'] = new_X.apply(lambda x: [lemm.lemmatize(word) for word in x['no_stopwords_tweet']], axis=1)\n        return new_X","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt = TweetTransformer()\ntt.fit(new_sample)\nttt = tt.transform(new_sample)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttt","execution_count":34,"outputs":[{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"         id  keyword                          location  \\\n15       46   ablaze                            London   \n16       47   ablaze    Niall's place | SAF 12 SQUAD |   \n17       51   ablaze                           NIGERIA   \n18       58   ablaze                    Live On Webcam   \n19       60   ablaze          Los Angeles, Califnordia   \n...     ...      ...                               ...   \n3247  10806  wrecked                Seattle Washington   \n3248  10807  wrecked  Acey mountain islanddåÇTorontoåÈ   \n3249  10816  wrecked                       los angeles   \n3250  10820  wrecked                 Brussels, Belgium   \n3251  10828  wrecked                               NaN   \n\n                                                   text  \\\n15    Birmingham Wholesale Market is ablaze BBC News...   \n16    @sunkxssedharry will you wear shorts for race ...   \n17    #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...   \n18    Check these out: http://t.co/rOI2NSmEJJ http:/...   \n19    PSA: IÛªm splitting my personalities.\\n\\n?? t...   \n...                                                 ...   \n3247  RT CNBC '3 words from Disney CEO Bob Iger wrec...   \n3248  Smackdown tyme this should put me in a good mo...   \n3249  @thrillhho jsyk I haven't stopped thinking abt...   \n3250  @stighefootball Begovic has been garbage. He g...   \n3251                 Wrecked today got my hattrick ????   \n\n                                         no_punct_tweet  \\\n15    birmingham wholesale market is ablaze bbc news...   \n16    sunkxssedharry will you wear shorts for race a...   \n17    previouslyondoyintv toke makinwaûªs marriage ...   \n18    check these out httptcoroi2nsmejj httptco3tj8z...   \n19    psa iûªm splitting my personalities\\n\\n techi...   \n...                                                 ...   \n3247  rt cnbc 3 words from disney ceo bob iger wreck...   \n3248  smackdown tyme this should put me in a good mo...   \n3249  thrillhho jsyk i havent stopped thinking abt r...   \n3250  stighefootball begovic has been garbage he got...   \n3251                     wrecked today got my hattrick    \n\n                                         tokenize_tweet  \\\n15    [birmingham, wholesale, market, is, ablaze, bb...   \n16    [sunkxssedharry, will, you, wear, shorts, for,...   \n17    [previouslyondoyintv, toke, makinwaûªs, marri...   \n18    [check, these, out, httptcoroi2nsmejj, httptco...   \n19    [psa, iûªm, splitting, my, personalities, tec...   \n...                                                 ...   \n3247  [rt, cnbc, 3, words, from, disney, ceo, bob, i...   \n3248  [smackdown, tyme, this, should, put, me, in, a...   \n3249  [thrillhho, jsyk, i, havent, stopped, thinking...   \n3250  [stighefootball, begovic, has, been, garbage, ...   \n3251                [wrecked, today, got, my, hattrick]   \n\n                                     no_stopwords_tweet  \\\n15    [birmingham, wholesale, market, ablaze, bbc, n...   \n16         [sunkxssedharry, wear, shorts, race, ablaze]   \n17    [previouslyondoyintv, toke, makinwaûªs, marri...   \n18    [check, httptcoroi2nsmejj, httptco3tj8zjin21, ...   \n19    [psa, iûªm, splitting, personalities, techies...   \n...                                                 ...   \n3247  [rt, cnbc, 3, words, disney, ceo, bob, iger, w...   \n3248  [smackdown, tyme, put, good, mood, since, got,...   \n3249  [thrillhho, jsyk, havent, stopped, thinking, a...   \n3250  [stighefootball, begovic, garbage, got, wrecke...   \n3251                    [wrecked, today, got, hattrick]   \n\n                                                   lemm  \n15    [birmingham, wholesale, market, ablaze, bbc, n...  \n16          [sunkxssedharry, wear, short, race, ablaze]  \n17    [previouslyondoyintv, toke, makinwaûªs, marri...  \n18    [check, httptcoroi2nsmejj, httptco3tj8zjin21, ...  \n19    [psa, iûªm, splitting, personality, techie, f...  \n...                                                 ...  \n3247  [rt, cnbc, 3, word, disney, ceo, bob, iger, wr...  \n3248  [smackdown, tyme, put, good, mood, since, got,...  \n3249  [thrillhho, jsyk, havent, stopped, thinking, a...  \n3250  [stighefootball, begovic, garbage, got, wrecke...  \n3251                    [wrecked, today, got, hattrick]  \n\n[3237 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>no_punct_tweet</th>\n      <th>tokenize_tweet</th>\n      <th>no_stopwords_tweet</th>\n      <th>lemm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>46</td>\n      <td>ablaze</td>\n      <td>London</td>\n      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n      <td>birmingham wholesale market is ablaze bbc news...</td>\n      <td>[birmingham, wholesale, market, is, ablaze, bb...</td>\n      <td>[birmingham, wholesale, market, ablaze, bbc, n...</td>\n      <td>[birmingham, wholesale, market, ablaze, bbc, n...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>47</td>\n      <td>ablaze</td>\n      <td>Niall's place | SAF 12 SQUAD |</td>\n      <td>@sunkxssedharry will you wear shorts for race ...</td>\n      <td>sunkxssedharry will you wear shorts for race a...</td>\n      <td>[sunkxssedharry, will, you, wear, shorts, for,...</td>\n      <td>[sunkxssedharry, wear, shorts, race, ablaze]</td>\n      <td>[sunkxssedharry, wear, short, race, ablaze]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>51</td>\n      <td>ablaze</td>\n      <td>NIGERIA</td>\n      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n      <td>previouslyondoyintv toke makinwaûªs marriage ...</td>\n      <td>[previouslyondoyintv, toke, makinwaûªs, marri...</td>\n      <td>[previouslyondoyintv, toke, makinwaûªs, marri...</td>\n      <td>[previouslyondoyintv, toke, makinwaûªs, marri...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>58</td>\n      <td>ablaze</td>\n      <td>Live On Webcam</td>\n      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n      <td>check these out httptcoroi2nsmejj httptco3tj8z...</td>\n      <td>[check, these, out, httptcoroi2nsmejj, httptco...</td>\n      <td>[check, httptcoroi2nsmejj, httptco3tj8zjin21, ...</td>\n      <td>[check, httptcoroi2nsmejj, httptco3tj8zjin21, ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>60</td>\n      <td>ablaze</td>\n      <td>Los Angeles, Califnordia</td>\n      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n      <td>psa iûªm splitting my personalities\\n\\n techi...</td>\n      <td>[psa, iûªm, splitting, my, personalities, tec...</td>\n      <td>[psa, iûªm, splitting, personalities, techies...</td>\n      <td>[psa, iûªm, splitting, personality, techie, f...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3247</th>\n      <td>10806</td>\n      <td>wrecked</td>\n      <td>Seattle Washington</td>\n      <td>RT CNBC '3 words from Disney CEO Bob Iger wrec...</td>\n      <td>rt cnbc 3 words from disney ceo bob iger wreck...</td>\n      <td>[rt, cnbc, 3, words, from, disney, ceo, bob, i...</td>\n      <td>[rt, cnbc, 3, words, disney, ceo, bob, iger, w...</td>\n      <td>[rt, cnbc, 3, word, disney, ceo, bob, iger, wr...</td>\n    </tr>\n    <tr>\n      <th>3248</th>\n      <td>10807</td>\n      <td>wrecked</td>\n      <td>Acey mountain islanddåÇTorontoåÈ</td>\n      <td>Smackdown tyme this should put me in a good mo...</td>\n      <td>smackdown tyme this should put me in a good mo...</td>\n      <td>[smackdown, tyme, this, should, put, me, in, a...</td>\n      <td>[smackdown, tyme, put, good, mood, since, got,...</td>\n      <td>[smackdown, tyme, put, good, mood, since, got,...</td>\n    </tr>\n    <tr>\n      <th>3249</th>\n      <td>10816</td>\n      <td>wrecked</td>\n      <td>los angeles</td>\n      <td>@thrillhho jsyk I haven't stopped thinking abt...</td>\n      <td>thrillhho jsyk i havent stopped thinking abt r...</td>\n      <td>[thrillhho, jsyk, i, havent, stopped, thinking...</td>\n      <td>[thrillhho, jsyk, havent, stopped, thinking, a...</td>\n      <td>[thrillhho, jsyk, havent, stopped, thinking, a...</td>\n    </tr>\n    <tr>\n      <th>3250</th>\n      <td>10820</td>\n      <td>wrecked</td>\n      <td>Brussels, Belgium</td>\n      <td>@stighefootball Begovic has been garbage. He g...</td>\n      <td>stighefootball begovic has been garbage he got...</td>\n      <td>[stighefootball, begovic, has, been, garbage, ...</td>\n      <td>[stighefootball, begovic, garbage, got, wrecke...</td>\n      <td>[stighefootball, begovic, garbage, got, wrecke...</td>\n    </tr>\n    <tr>\n      <th>3251</th>\n      <td>10828</td>\n      <td>wrecked</td>\n      <td>NaN</td>\n      <td>Wrecked today got my hattrick ????</td>\n      <td>wrecked today got my hattrick</td>\n      <td>[wrecked, today, got, my, hattrick]</td>\n      <td>[wrecked, today, got, hattrick]</td>\n      <td>[wrecked, today, got, hattrick]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3237 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ntransformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(), [1])])\ntransformer.fit_transform(new_sample)\ntransformer","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n                  transformer_weights=None,\n                  transformers=[('cat',\n                                 OneHotEncoder(categorical_features=None,\n                                               categories=None, drop=None,\n                                               dtype=<class 'numpy.float64'>,\n                                               handle_unknown='error',\n                                               n_values=None, sparse=True),\n                                 [1])],\n                  verbose=False)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# no_punt = str.maketrans('', '', punctuation)\n\n# def remove_punctuation(text):\n#     no_punct_text = \"\".join([char for char in text if char not in punctuation])\n#     return no_punct_text\n\n# new = test\n# new['text'] = new['text'].apply(lambda x: remove_punctuation(x.lower()))\n# new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}